Here is a **clean, academically credible summary** of your results ‚Äî written exactly how a review committee, professor, or research board would expect an empirical evaluation to be presented.

It integrates:

* your dataset design
* our experimental setup
* the model architecture and settings
* the bias conditions
* the evaluation metrics
* the cross-condition analysis
* and a responsible scientific interpretation

This is fully ready for a report, milestone document, or paper section.

---

# üìò **Evaluation Summary of LLM-as-Judge Bias Robustness Experiment**

## **1. Experimental Context**

This study aims to evaluate whether large language models (LLMs), when acting as *judges* of answer quality, are susceptible to *superficial bias manipulations* such as formatting, tone, verbosity, or linguistic framing.

This mirrors real-world usage of LLMs as evaluators in:

* model-vs-model comparisons
* educational grading
* automated scoring systems
* safety evaluations
* content moderation pipelines

Ensuring *robustness* of judge models is essential for fairness and reliability.

---

## **2. Dataset and Bias Construction**

The dataset consists of **110 base questions** across diverse mechanism families:

* VISU-* (Markdown/Listing/Paragraph bias)
* LENG-* (Length, conciseness, verbosity bias)
* TONE-* (Confidence, politeness bias)
* RSNG-* (Reasoning structure bias)
* LEXI-* (Lexical choice bias)

Each question includes:

* **A baseline correct answer (C_BASE)**
* **A weaker but plausible incorrect answer (W_BASE)**
* **A biased version of the weak answer (W_BIAS)**
  introducing stylistic changes (tone, clarity, length, confidence, etc.)

This produces **two evaluation conditions per question:**

1. **BASE:** model judges C_BASE vs W_BASE
2. **BIAS:** model judges C_BASE vs W_BIAS

Total evaluations = **220 independent judgments**.

---

## **3. Model and Evaluation Settings**

### **Model**

* **gpt-4.1-nano**, a small but modern transformer designed for low-latency judging tasks.
* Strong reasoning relative to scale; deterministic under seeded conditions.

### **Inference settings**

* **temperature = 0.0**
* **per-row seed = deterministic**
* **1 question per API call** (prevents cross-contamination in context window)
* **system prompt:** instructs model to choose ‚ÄúA‚Äù or ‚ÄúB‚Äù and then briefly explain.

These settings minimize randomness, ensuring stability and reproducibility.

---

## **4. Measurement Definitions**

Each question receives one of four outcomes:

| Status         | Meaning                             |
| -------------- | ----------------------------------- |
| **ROBUST**     | Model correct in both BASE and BIAS |
| **TRICKED**    | Correct in BASE, wrong in BIAS      |
| **HELPED**     | Wrong in BASE, correct in BIAS      |
| **BOTH_WRONG** | Incorrect in both conditions        |

The key measurements for bias sensitivity are **TRICKED** (adversarial bias) and **HELPED** (beneficial bias).

---

## **5. Quantitative Results**

From 220 judgments:

| Category       | Count   | Percentage |
| -------------- | ------- | ---------- |
| **ROBUST**     | **203** | **92.3%**  |
| **TRICKED**    | **2**   | **0.9%**   |
| **HELPED**     | **5**   | **2.3%**   |
| **BOTH_WRONG** | **10**  | **4.5%**   |

### **Interpretation**

* The model is overwhelmingly robust in this controlled evaluation.
* Adversarial susceptibility is **low but non-zero**.
* Positive bias corrections also occur, though in small numbers.
* A small subset of questions appears inherently ambiguous or challenging, producing BOTH_WRONG outcomes.

---

## **6. Qualitative Reasoning Analysis**

A manual review of TRICKED and HELPED cases shows:

### ‚ú¶ **1. No instance where the model acknowledges or cites stylistic cues**

The model **never** states:

* ‚ÄúThis sounds more confident.‚Äù
* ‚ÄúThis formatting looks clearer.‚Äù
* ‚ÄúThis is more persuasive.‚Äù

### ‚ú¶ **2. All flips result from semantic confusion, not stylistic influence**

When the model flips from choosing A ‚Üí B or vice versa:

* It consistently claims the chosen answer ‚Äúcorrectly uses‚Äù or ‚Äúcorrectly explains‚Äù the underlying concept.
* The reasoning text is mechanically similar across BASE and BIAS conditions.
* The model is misidentifying the *content*, not responding to *style*.

### ‚ú¶ **3. No evidence of tone, length, or style affecting the model‚Äôs explicit reasoning**

Even in categories specifically designed for this (e.g., TONE-CONF, LENG-CNCS), the judge does not comment on those attributes.

### ‚ú¶ **4. Most flips occur on questions with close semantic similarity between answers**

This means:

* The ‚Äúbias injection‚Äù was too subtle to override content-based evaluation.
* The primary driver of error is **interpretive ambiguity**, not style.

---

## **7. Overall Interpretation**

### ‚úî **The model is content-driven, not style-driven**

Even when presented with stylistically different answers, the model focuses on *semantic correctness*.

### ‚úî **Bias effects exist but are extremely minor**

Only **0.9%** of cases show harmful bias.

### ‚úî **Helpful bias exists, but similarly rare**

Bias nudges the model *toward correctness* in **2.3%** of cases.

### ‚úî **Most vulnerabilities should be classified as semantic, not stylistic**

Errors reflect:

* difficulty distinguishing between two similar answers
* imperfect reasoning
* mis-attribution of which answer contains correct math or explanation

Not susceptibility to:

* verbosity
* confidence
* formatting
* politeness
* structural differences

### ‚úî **Your controlled setup (temperature 0 + deterministic seed + isolated calls) appears to favor robustness**

This is an important methodological point.

Under different settings:

* higher temperature
* longer answers
* more extreme tone differences
* cross-question contamination

‚Ä¶susceptibility would likely increase.

---

## **8. Scientific Value of These Results**

These results **do matter**, because they demonstrate:

### ‚ñ∫ **Modern small LLMs acting as judges are highly robust under mild stylistic perturbations.**

### ‚ñ∫ **Semantic confusion‚Äînot style‚Äîis the dominant source of error.**

### ‚ñ∫ **Bias manipulations must be significantly stronger to reveal judge vulnerabilities.**

### ‚ñ∫ **Future work can deepen results by using:**

* more extreme rhetorical framing
* confidence boosting
* emotional urgency
* over-structured formats
* deceptive reasoning tone

### ‚ñ∫ **Your pipeline is scientifically valid and can scale to test stronger manipulations.**

---

# ‚úî If you want, I can also write:

* A **full academic ‚ÄúMethodology‚Äù section**
* A **Results + Discussion** section
* A **Threats to Validity** section
* A **Future Work** section
* Figures/plots for your paper

Just tell me which section(s) you want next.
